{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Daniyal\\Personal Projects\\Toxic Comments\\toxic_comments\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel,BertTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating BERT Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicityModel(nn.Module):\n",
    "    def __init__(self, bert_model):\n",
    "        super(ToxicityModel,self).__init__()\n",
    "        \n",
    "        self.bert_model = bert_model\n",
    "                \n",
    "        self.l1 = nn.Linear(768,256)  ## Reducing the Vector Dimension\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        ## ['target','severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']\n",
    "        self.toxicity = nn.Linear(256,6)  ## 6 classes\n",
    "        \n",
    "        self.bert_model.train() ## Setting up bert model on training mode by default\n",
    "        \n",
    "    def forward(self,**kwargs):\n",
    "        \n",
    "        hc,_ = self.bert_model(**kwargs,return_dict = False)\n",
    "        x = hc[:,0,:]\n",
    "        x = self.dropout(self.l1(x))\n",
    "        x = self.toxicity(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(\"../bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToxicityModel(bert_model=bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"../bert_model\",do_lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer(\n",
    "                    \"Hello! How are you!\",padding='max_length',\n",
    "                    max_length = 128,return_tensors = \"pt\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(**text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert out.shape == torch.Size([1,6])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicityDataset(Dataset):\n",
    "    def __init__(self,data_path,tokenizer,max_length = 128):\n",
    "        ## Initializing some variables in the constructor\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = 128\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        ## Accessing the single item\n",
    "        item = self.data.iloc[idx]\n",
    "        \n",
    "        ## The input comment text\n",
    "        comment_text = item['comment_text']\n",
    "        \n",
    "        ## The output labels\n",
    "        toxicity = item['target_label']\n",
    "        severe_toxicity = item['severe_toxicity']\n",
    "        obscene = item['obscene']\n",
    "        identity_attack = item['identity_attack']\n",
    "        insult = item['insult']\n",
    "        threat = item['threat']\n",
    "        \n",
    "        ## tokenizing the text\n",
    "        input_tensors = tokenizer(comment_text,padding=\"max_length\",\\\n",
    "                                    max_length=self.max_length,truncation=True,\\\n",
    "                                         return_tensors = \"pt\")\n",
    "        \n",
    "        ## Reducing a dimension for each key\n",
    "        input_tensors = {k:v.squeeze(0) for k,v in input_tensors.items()}\n",
    "        \n",
    "        ## Processing the output labels\n",
    "        labels = [toxicity,severe_toxicity,obscene,identity_attack,insult,threat]\n",
    "        labels = torch.tensor(labels).long()\n",
    "        \n",
    "        ## returning the result\n",
    "        return {\"input\":input_tensors,\"labels\":labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "unittest_dataset = ToxicityDataset(\"../data/train_split.csv\",tokenizer=tokenizer,max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = unittest_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert out['input']['input_ids'].shape == torch.Size([128]), \"Incorrect Max length generated from Dataloader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert out['labels'].shape == torch.Size([6]), \"Incorrect Number of labels generated from the Dataloader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory ../bert_model/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m BertModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39m../bert_model/\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Daniyal\\Personal Projects\\Toxic Comments\\toxic_comments\\lib\\site-packages\\transformers\\modeling_utils.py:2274\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2268\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2269\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError no file named \u001b[39m\u001b[39m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[39m \u001b[39mvariant)\u001b[39m}\u001b[39;00m\u001b[39m found in directory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2270\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m but there is a file for Flax weights. Use `from_flax=True`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2271\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m to load this model from those weights.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2272\u001b[0m         )\n\u001b[0;32m   2273\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2274\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2275\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError no file named \u001b[39m\u001b[39m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[39m \u001b[39mvariant)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2276\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m or \u001b[39m\u001b[39m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m found in directory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2277\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2278\u001b[0m         )\n\u001b[0;32m   2279\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(subfolder, pretrained_model_name_or_path)):\n\u001b[0;32m   2280\u001b[0m     archive_file \u001b[39m=\u001b[39m pretrained_model_name_or_path\n",
      "\u001b[1;31mOSError\u001b[0m: Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory ../bert_model/."
     ]
    }
   ],
   "source": [
    "# model = BertModel.from_pretrained(\"../bert_model/\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxic_comments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
