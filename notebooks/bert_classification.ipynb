{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel,BertTokenizer,BertConfig,get_linear_schedule_with_warmup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating BERT Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicityModel(nn.Module):\n",
    "    def __init__(self, bert_model):\n",
    "        super(ToxicityModel,self).__init__()\n",
    "        \n",
    "        self.bert_model = bert_model\n",
    "                \n",
    "        self.l1 = nn.Linear(768,256)  ## Reducing the Vector Dimension\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        ## ['target','severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']\n",
    "        self.toxicity = nn.Linear(256,6)  ## 6 classes\n",
    "        \n",
    "        self.bert_model.train() ## Setting up bert model on training mode by default\n",
    "        \n",
    "    def forward(self,**kwargs):\n",
    "        \n",
    "        hc,_ = self.bert_model(**kwargs,return_dict = False)\n",
    "        x = hc[:,0,:]\n",
    "        x = self.dropout(self.l1(x))\n",
    "        x = self.toxicity(x)\n",
    "        \n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "    def training_step(self,input,label,loss_fn):\n",
    "        \n",
    "        out = self(**input)\n",
    "        loss = loss_fn(out,label)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(\"../bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_config = BertConfig.from_pretrained(\"../bert_model/\")\n",
    "# bert_model = BertModel(config=bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToxicityModel(bert_model=bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"../bert_model\",do_lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer(\n",
    "                    \"Hello! How are you!\",padding='max_length',\n",
    "                    max_length = 128,return_tensors = \"pt\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(**text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert out.shape == torch.Size([1,6])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicityDataset(Dataset):\n",
    "    def __init__(self,data_path,tokenizer,max_length = 128):\n",
    "        ## Initializing some variables in the constructor\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = 128\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        ## Accessing the single item\n",
    "        item = self.data.iloc[idx]\n",
    "        \n",
    "        ## The input comment text\n",
    "        comment_text = item['comment_text']\n",
    "        \n",
    "        ## The output labels\n",
    "        toxicity = item['target_label']\n",
    "        severe_toxicity = item['severe_toxicity']\n",
    "        obscene = item['obscene']\n",
    "        identity_attack = item['identity_attack']\n",
    "        insult = item['insult']\n",
    "        threat = item['threat']\n",
    "        \n",
    "        ## tokenizing the text\n",
    "        input_tensors = tokenizer(comment_text,padding=\"max_length\",\\\n",
    "                                    max_length=self.max_length,truncation=True,\\\n",
    "                                         return_tensors = \"pt\")\n",
    "        \n",
    "        ## Reducing a dimension for each key\n",
    "        input_tensors = {k:v.squeeze(0) for k,v in input_tensors.items()}\n",
    "        \n",
    "        ## Processing the output labels\n",
    "        labels = [toxicity,severe_toxicity,obscene,identity_attack,insult,threat]\n",
    "        labels = torch.tensor(labels,dtype=torch.float32)\n",
    "        \n",
    "        ## returning the result\n",
    "        return {\"input\":input_tensors,\"labels\":labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "unittest_dataset = ToxicityDataset(\"../data/train_split.csv\",tokenizer=tokenizer,max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = unittest_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert out['input']['input_ids'].shape == torch.Size([128]), \"Incorrect Max length generated from Dataloader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert out['labels'].shape == torch.Size([6]), \"Incorrect Number of labels generated from the Dataloader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory ../bert_model/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m BertModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39m../bert_model/\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Daniyal\\Personal Projects\\Toxic Comments\\toxic_comments\\lib\\site-packages\\transformers\\modeling_utils.py:2274\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2268\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2269\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError no file named \u001b[39m\u001b[39m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[39m \u001b[39mvariant)\u001b[39m}\u001b[39;00m\u001b[39m found in directory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2270\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m but there is a file for Flax weights. Use `from_flax=True`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2271\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m to load this model from those weights.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2272\u001b[0m         )\n\u001b[0;32m   2273\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2274\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2275\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError no file named \u001b[39m\u001b[39m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[39m \u001b[39mvariant)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2276\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m or \u001b[39m\u001b[39m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m found in directory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2277\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2278\u001b[0m         )\n\u001b[0;32m   2279\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(subfolder, pretrained_model_name_or_path)):\n\u001b[0;32m   2280\u001b[0m     archive_file \u001b[39m=\u001b[39m pretrained_model_name_or_path\n",
      "\u001b[1;31mOSError\u001b[0m: Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory ../bert_model/."
     ]
    }
   ],
   "source": [
    "# model = BertModel.from_pretrained(\"../bert_model/\",)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 100\n",
    "device  = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset\n",
    "train_dataset = ToxicityDataset(\"../data/train_split.csv\",tokenizer=tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "### Validation\n",
    "valid_dataset = ToxicityDataset(\"../data/validate.csv\",tokenizer=tokenizer)\n",
    "valid_dataloader = DataLoader(valid_dataset,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "total_steps = (len(train_dataloader) //batch_size) * epochs\n",
    "\n",
    "num_warmup_steps = total_steps//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.0001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=num_warmup_steps,\n",
    "  num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6494, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "log_train_loss = []\n",
    "log_val_loss = []\n",
    "best_loss = -999\n",
    "\n",
    "\n",
    "train_losses = 0\n",
    "valid_losses = 0 \n",
    "model.train()\n",
    "for batch in train_dataloader:\n",
    "    \n",
    "    batch['input'] = {k:v.to(device) for k,v in batch['input'].items()}\n",
    "    batch['labels'] = batch['labels'].to(device)\n",
    "    \n",
    "    loss = model.training_step(batch['input'],batch['labels'],loss_fn)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    train_losses+=loss.detach().cpu().item()\n",
    "    break\n",
    "    \n",
    "log_train_loss.append(train_losses/len(train_dataloader))\n",
    "\n",
    "model.eval()\n",
    "for batch in valid_dataloader:\n",
    "    \n",
    "    batch['input'] = {k:v.to(device) for k,v in batch['input'].items()}\n",
    "    batch['labels'] = batch['labels'].to(device)        \n",
    "    loss = model.training_step(batch['input'],batch['labels'],loss_fn)\n",
    "\n",
    "    valid_losses+=loss.detach().cpu().item()\n",
    "    \n",
    "log_val_loss.append(valid_losses/len(valid_dataloader))\n",
    "\n",
    "\n",
    "if log_val_loss[-1] < best_loss:\n",
    "    best_loss = log_val_loss[-1]\n",
    "    torch.save(model.parameters(),\"../model/best.pt\")\n",
    "\n",
    "if (i % 5 == 0):\n",
    "    print(f\"Train loss : {log_train_loss[-1]}  Valid loss : {log_val_loss[-1]}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/train_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6258663</td>\n",
       "      <td>Like you , Peter , I wish others not on the wa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>345645</td>\n",
       "      <td>`` I wont support anyone wayerhouser sells to ...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5283043</td>\n",
       "      <td>The number one thing a con con can do is de ce...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>649896</td>\n",
       "      <td>Yes , but have they been CONVINCINGLY answered...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6302894</td>\n",
       "      <td>See also Sinclair Lewis  prescient 1935 novel ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                       comment_text  \\\n",
       "0  6258663  Like you , Peter , I wish others not on the wa...   \n",
       "1   345645  `` I wont support anyone wayerhouser sells to ...   \n",
       "2  5283043  The number one thing a con con can do is de ce...   \n",
       "3   649896  Yes , but have they been CONVINCINGLY answered...   \n",
       "4  6302894  See also Sinclair Lewis  prescient 1935 novel ...   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack  insult  threat  target_label  \n",
       "0              0.0      0.0              0.0     0.0     0.0             0  \n",
       "1              0.1      0.0              0.1     0.3     0.6             1  \n",
       "2              0.0      0.0              0.0     0.0     0.0             0  \n",
       "3              0.0      0.0              0.0     0.0     0.0             0  \n",
       "4              0.0      0.0              0.0     0.0     0.0             0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Daniyal\\Personal Projects\\Toxic Comments\\toxic_comments\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(data) * 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = range(0,len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random.sample(total_size,k = size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.iloc[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1338812</th>\n",
       "      <td>5751593</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>I just find phony conservatives amazing in not...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365468</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629736</th>\n",
       "      <td>6118151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IMDb.com tells me that the Hollywood lefties l...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>387336</td>\n",
       "      <td>approved</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276045</th>\n",
       "      <td>580412</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Pepe, don't forget Lisa Murkowski's wholesale ...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>150726</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>315362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>“We change our tax as much as we change our un...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>97560</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837369</th>\n",
       "      <td>5145294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Just bought a Silverado with 212 k.  Chevy is ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>327656</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id    target                                       comment_text  \\\n",
       "1338812  5751593  0.552632  I just find phony conservatives amazing in not...   \n",
       "1629736  6118151  0.000000  IMDb.com tells me that the Hollywood lefties l...   \n",
       "276045    580412  0.200000  Pepe, don't forget Lisa Murkowski's wholesale ...   \n",
       "59941     315362  0.000000  “We change our tax as much as we change our un...   \n",
       "837369   5145294  0.000000  Just bought a Silverado with 212 k.  Chevy is ...   \n",
       "\n",
       "         severe_toxicity   obscene  identity_attack    insult  threat  asian  \\\n",
       "1338812              0.0  0.065789         0.065789  0.539474     0.0    0.0   \n",
       "1629736              0.0  0.000000         0.000000  0.000000     0.0    NaN   \n",
       "276045               0.1  0.000000         0.000000  0.100000     0.1    NaN   \n",
       "59941                0.0  0.000000         0.000000  0.000000     0.0    NaN   \n",
       "837369               0.0  0.000000         0.000000  0.000000     0.0    NaN   \n",
       "\n",
       "         atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "1338812      0.0  ...      365468  approved      1    0    0      1         4   \n",
       "1629736      NaN  ...      387336  approved      2    0    1      1         4   \n",
       "276045       NaN  ...      150726  approved      0    0    0      0         0   \n",
       "59941        NaN  ...       97560  approved      0    0    0      7         0   \n",
       "837369       NaN  ...      327656  approved      1    0    1      3         0   \n",
       "\n",
       "         sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "1338812              0.0                         4                        76  \n",
       "1629736              0.0                         0                         4  \n",
       "276045               0.0                         0                        10  \n",
       "59941                0.0                         0                         4  \n",
       "837369               0.0                         0                         4  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv(\"../data/sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing the evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions,labels,threshold):\n",
    "    \n",
    "    norm = torch.where(predictions>=threshold,1,0)\n",
    "    accuracy,f1 = accuracy_score(predictions,labels),f1_score(predictions,labels,average=\"micro\")\n",
    "    \n",
    "    lb_name = ['toxicity','severe_toxicity','obscene','identity_attack','insult','threat']\n",
    "    report = classification_report(labels,norm, target_names=lb_name)\n",
    "    \n",
    "    return accuracy,f1,report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.where(x > 0.5,1,0)\n",
    "predictions = torch.where(torch.rand(5,6) > 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,report = evaluate(predictions,label,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       toxicity       0.67      0.67      0.67         3\n",
      "severe_toxicity       1.00      1.00      1.00         3\n",
      "        obscene       0.50      0.67      0.57         3\n",
      "identity_attack       0.50      0.50      0.50         2\n",
      "         insult       0.33      1.00      0.50         1\n",
      "         threat       0.67      0.67      0.67         3\n",
      "\n",
      "      micro avg       0.61      0.73      0.67        15\n",
      "      macro avg       0.61      0.75      0.65        15\n",
      "   weighted avg       0.66      0.73      0.68        15\n",
      "    samples avg       0.60      0.77      0.65        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxic_comments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
